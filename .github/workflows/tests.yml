name: ADX-Agent Test Suite

on:
  push:
    branches: [ main, develop, feature/* ]
  pull_request:
    branches: [ main, develop ]
  schedule:
    # Run tests daily at 2 AM UTC
    - cron: '0 2 * * *'

env:
  NODE_VERSION: '18'
  PYTHON_VERSION: '3.11'

jobs:
  # Unit Tests
  frontend-unit-tests:
    name: Frontend Unit Tests
    runs-on: ubuntu-latest
    
    services:
      redis:
        image: redis:7-alpine
        ports:
          - 6379:6379
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: ${{ env.NODE_VERSION }}
        cache: 'npm'
        cache-dependency-path: 'frontend/package-lock.json'
        
    - name: Install frontend dependencies
      working-directory: ./frontend
      run: npm ci
      
    - name: Run TypeScript type checking
      working-directory: ./frontend
      run: npm run type-check
      
    - name: Run ESLint
      working-directory: ./frontend
      run: npm run lint
      
    - name: Run unit tests with coverage
      working-directory: ./frontend
      run: npm run test:coverage
      env:
        CI: true
        NODE_ENV: test
        
    - name: Upload frontend test results
      uses: codecov/codecov-action@v3
      with:
        file: ./frontend/coverage/lcov.info
        flags: frontend
        name: frontend-coverage
        
    - name: Upload frontend test artifacts
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: frontend-test-results
        path: |
          frontend/coverage/
          frontend/test-results/
          frontend/junit.xml

  backend-unit-tests:
    name: Backend Unit Tests
    runs-on: ubuntu-latest
    
    services:
      postgres:
        image: postgres:15-alpine
        env:
          POSTGRES_USER: testuser
          POSTGRES_PASSWORD: testpass
          POSTGRES_DB: adx_agent_test
        ports:
          - 5432:5432
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
          
      redis:
        image: redis:7-alpine
        ports:
          - 6379:6379
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
        
    - name: Install Python dependencies
      working-directory: ./backend
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest pytest-asyncio pytest-cov pytest-html pytest-xdist httpx
        
    - name: Run database migrations
      working-directory: ./backend
      run: python -m alembic upgrade head
      env:
        DATABASE_URL: postgresql://testuser:testpass@localhost:5432/adx_agent_test
        
    - name: Run backend unit tests
      working-directory: ./backend
      run: |
        pytest tests/unit/ \
          --cov=app \
          --cov-report=xml \
          --cov-report=html \
          --junit-xml=../backend-junit.xml \
          --html=../backend-report.html \
          --self-contained-html
      env:
        DATABASE_URL: postgresql://testuser:testpass@localhost:5432/adx_agent_test
        REDIS_URL: redis://localhost:6379/0
        E2B_API_KEY: test_key
        GOOGLE_GENERATIVE_AI_API_KEY: test_key
        JWT_SECRET: test_jwt_secret
        ENCRYPTION_KEY: test_encryption_key
        
    - name: Upload backend test results
      uses: codecov/codecov-action@v3
      with:
        file: ./backend/coverage.xml
        flags: backend
        name: backend-coverage
        
    - name: Upload backend test artifacts
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: backend-test-results
        path: |
          backend/coverage.xml
          backend/htmlcov/
          backend-junit.xml
          backend-report.html

  # Integration Tests
  api-integration-tests:
    name: API Integration Tests
    runs-on: ubuntu-latest
    needs: [frontend-unit-tests, backend-unit-tests]
    
    services:
      postgres:
        image: postgres:15-alpine
        env:
          POSTGRES_USER: testuser
          POSTGRES_PASSWORD: testpass
          POSTGRES_DB: adx_agent_test
        ports:
          - 5432:5432
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
          
      redis:
        image: redis:7-alpine
        ports:
          - 6379:6379
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
        
    - name: Install Python dependencies
      working-directory: ./backend
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest pytest-asyncio pytest-html httpx fastapi[all]
        
    - name: Run database migrations
      working-directory: ./backend
      run: python -m alembic upgrade head
      env:
        DATABASE_URL: postgresql://testuser:testpass@localhost:5432/adx_agent_test
        
    - name: Start backend server for integration tests
      working-directory: ./backend
      run: |
        uvicorn main:app --host 127.0.0.1 --port 8000 &
      env:
        DATABASE_URL: postgresql://testuser:testpass@localhost:5432/adx_agent_test
        REDIS_URL: redis://localhost:6379/0
        E2B_API_KEY: test_key
       AI_API_KEY: GOOGLE_GENERATIVE_ test_key
        JWT_SECRET: test_jwt_secret
        ENCRYPTION_KEY: test_encryption_key
        
    - name: Wait for backend to be ready
      run: |
        timeout 60 bash -c 'until curl -f http://127.0.0.1:8000/health; do sleep 2; done'
        
    - name: Run API integration tests
      working-directory: ./backend
      run: |
        pytest tests/integration/ \
          --junit-xml=../integration-junit.xml \
          --html=../integration-report.html \
          --self-contained-html
      env:
        API_BASE_URL: http://127.0.0.1:8000
        E2B_API_KEY: test_key
        GOOGLE_GENERATIVE_AI_API_KEY: test_key
        
    - name: Upload integration test artifacts
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: integration-test-results
        path: |
          integration-junit.xml
          integration-report.html

  # E2E Tests
  e2e-tests:
    name: End-to-End Tests
    runs-on: ubuntu-latest
    needs: [api-integration-tests]
    
    strategy:
      matrix:
        browser: [chromium, firefox, webkit]
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: ${{ env.NODE_VERSION }}
        cache: 'npm'
        cache-dependency-path: 'frontend/package-lock.json'
        
    - name: Install frontend dependencies
      working-directory: ./frontend
      run: npm ci
      
    - name: Build frontend for E2E tests
      working-directory: ./frontend
      run: npm run build
      env:
        NEXT_PUBLIC_API_URL: http://localhost:8000
        NODE_ENV: test
        
    - name: Install Playwright
      working-directory: ./frontend
      run: npx playwright install --with-deps
      
    - name: Run Playwright E2E tests
      working-directory: ./frontend
      run: npx playwright test --project=${{ matrix.browser }}
      env:
        CI: true
        
    - name: Upload E2E test results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: e2e-test-results-${{ matrix.browser }}
        path: |
          frontend/test-results/
          frontend/playwright-report/
          
    - name: Upload E2E test screenshots
      uses: actions/upload-artifact@v4
      if: failure()
      with:
        name: e2e-screenshots-${{ matrix.browser }}
        path: frontend/test-results/

  # Desktop Service Tests
  desktop-service-tests:
    name: Desktop Service Tests
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: ${{ env.NODE_VERSION }}
        
    - name: Test desktop service structure
      run: |
        echo "Testing desktop service configuration..."
        
        # Check if Dockerfile exists and is valid
        if [ -f "desktop/app/Dockerfile" ]; then
          echo "✅ Desktop Dockerfile found"
        else
          echo "❌ Desktop Dockerfile not found"
          exit 1
        fi
        
        # Check if startup script exists
        if [ -f "desktop/app/startup.sh" ]; then
          echo "✅ Desktop startup script found"
          # Make sure it's executable
          chmod +x desktop/app/startup.sh
        else
          echo "❌ Desktop startup script not found"
          exit 1
        fi
        
        # Check if config directory exists
        if [ -d "desktop/config" ]; then
          echo "✅ Desktop config directory found"
        else
          echo "❌ Desktop config directory not found"
          exit 1
        fi
        
        echo "✅ Desktop service structure validation passed"

  # Security Tests
  security-tests:
    name: Security Tests
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        
    - name: Install security testing tools
      run: |
        python -m pip install --upgrade pip
        pip install bandit safety semgrep
        
    - name: Run Bandit security linter
      working-directory: ./backend
      run: |
        bandit -r app/ -f json -o ../bandit-report.json || true
        
    - name: Run Safety dependency check
      working-directory: ./backend
      run: |
        safety check --json --output ../safety-report.json || true
        
    - name: Run Semgrep SAST scan
      run: |
        semgrep --config=auto --json --output=semgrep-report.json . || true
        
    - name: Upload security test results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: security-test-results
        path: |
          bandit-report.json
          safety-report.json
          semgrep-report.json

  # Performance Tests
  performance-tests:
    name: Performance Tests
    runs-on: ubuntu-latest
    needs: [api-integration-tests]
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: ${{ env.NODE_VERSION }}
        
    - name: Install performance testing tools
      run: npm install -g lighthouse artillery
      
    - name: Build frontend for performance testing
      working-directory: ./frontend
      run: npm run build
      env:
        NEXT_PUBLIC_API_URL: http://localhost:8000
        NODE_ENV: production
        
    - name: Start servers for performance testing
      working-directory: ./frontend
      run: |
        npm start &
        sleep 10
        
    - name: Run Lighthouse performance audit
      run: |
        lighthouse http://localhost:3000 \
          --only-categories=performance \
          --output=json \
          --output-path=lighthouse-performance.json \
          --quiet
          
    - name: Run Artillery load testing
      run: |
        cat > artillery-config.yml << 'EOF'
        config:
          target: 'http://localhost:8000'
          phases:
            - duration: 60
              arrivalRate: 10
            - duration: 120
              arrivalRate: 20
          defaults:
            headers:
              Content-Type: 'application/json'
        scenarios:
          - name: "API Health Check"
            weight: 50
            request:
              url: "/health"
              method: "GET"
          - name: "API Chat Endpoint"
            weight: 50
            request:
              url: "/api/chat"
              method: "POST"
              json:
                message: "test message"
                context: "performance test"
        EOF
        artillery run artillery-config.yml
        
    - name: Upload performance test results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: performance-test-results
        path: |
          lighthouse-performance.json
          artillery-report.html
          artillery-results.json

  # Docker Tests
  docker-tests:
    name: Docker Tests
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Test Docker builds
      run: |
        echo "Testing Docker builds..."
        
        # Test backend Docker build
        if [ -f "backend/docker/Dockerfile" ]; then
          echo "Testing backend Docker build..."
          docker build -f backend/docker/Dockerfile -t adx-agent-backend:test backend/
        fi
        
        # Test frontend Docker build
        if [ -f "frontend/docker/Dockerfile" ]; then
          echo "Testing frontend Docker build..."
          docker build -f frontend/docker/Dockerfile -t adx-agent-frontend:test frontend/
        fi
        
        # Test desktop Docker build
        if [ -f "desktop/docker/Dockerfile" ]; then
          echo "Testing desktop Docker build..."
          docker build -f desktop/docker/Dockerfile -t adx-agent-desktop:test desktop/
        fi
        
        echo "✅ All Docker builds successful"
        
    - name: Test Docker Compose
      run: |
        echo "Testing Docker Compose configuration..."
        
        # Validate docker-compose.yml syntax
        if [ -f "infrastructure/docker/docker-compose.dev.yml" ]; then
          docker-compose -f infrastructure/docker/docker-compose.dev.yml config > /dev/null
          echo "✅ Development Docker Compose configuration valid"
        fi
        
        if [ -f "infrastructure/docker/docker-compose.prod.yml" ]; then
          docker-compose -f infrastructure/docker/docker-compose.prod.yml config > /dev/null
          echo "✅ Production Docker Compose configuration valid"
        fi

  # Test Summary
  test-summary:
    name: Test Summary
    runs-on: ubuntu-latest
    needs: [
      frontend-unit-tests,
      backend-unit-tests,
      api-integration-tests,
      e2e-tests,
      desktop-service-tests,
      security-tests,
      performance-tests,
      docker-tests
    ]
    if: always()
    
    steps:
    - name: Download all artifacts
      uses: actions/download-artifact@v4
      
    - name: Test Results Summary
      run: |
        echo "# ADX-Agent Test Summary" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        # Check test results
        echo "## Test Results" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        if [ -d "frontend-test-results" ]; then
          echo "✅ Frontend Unit Tests: Passed" >> $GITHUB_STEP_SUMMARY
        else
          echo "❌ Frontend Unit Tests: Failed" >> $GITHUB_STEP_SUMMARY
        fi
        
        if [ -d "backend-test-results" ]; then
          echo "✅ Backend Unit Tests: Passed" >> $GITHUB_STEP_SUMMARY
        else
          echo "❌ Backend Unit Tests: Failed" >> $GITHUB_STEP_SUMMARY
        fi
        
        if [ -d "integration-test-results" ]; then
          echo "✅ Integration Tests: Passed" >> $GITHUB_STEP_SUMMARY
        else
          echo "❌ Integration Tests: Failed" >> $GITHUB_STEP_SUMMARY
        fi
        
        if [ -d "e2e-test-results-chromium" ] || [ -d "e2e-test-results-firefox" ]; then
          echo "✅ E2E Tests: Passed" >> $GITHUB_STEP_SUMMARY
        else
          echo "❌ E2E Tests: Failed" >> $GITHUB_STEP_SUMMARY
        fi
        
        if [ -d "security-test-results" ]; then
          echo "✅ Security Tests: Passed" >> $GITHUB_STEP_SUMMARY
        else
          echo "⚠️ Security Tests: Issues Found" >> $GITHUB_STEP_SUMMARY
        fi
        
        if [ -d "performance-test-results" ]; then
          echo "✅ Performance Tests: Passed" >> $GITHUB_STEP_SUMMARY
        else
          echo "❌ Performance Tests: Failed" >> $GITHUB_STEP_SUMMARY
        fi
        
        if [ -d "docker-test-results" ]; then
          echo "✅ Docker Tests: Passed" >> $GITHUB_STEP_SUMMARY
        else
          echo "❌ Docker Tests: Failed" >> $GITHUB_STEP_SUMMARY
        fi
        
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "## Artifacts" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "Test artifacts are available for download from this workflow run." >> $GITHUB_STEP_SUMMARY
        
    - name: Fail on test failures
      run: |
        # Check if any critical tests failed
        if [ ! -d "frontend-test-results" ] || [ ! -d "backend-test-results" ]; then
          echo "❌ Critical tests failed - failing the workflow"
          exit 1
        fi
        
        echo "✅ All critical tests passed"